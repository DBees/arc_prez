---
title: "Abstraction and Reasoning Challenge: Kaggle's Toughest Competition"
author: "Matthew Emery"
date: "7/8/2020"
bibliography: bib.tex
output: 
  revealjs::revealjs_presentation:
    theme: night
    css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## TODOs

 - Bibliography

---

![](img/easy1.png)

---

![](img/easy2.png)

## Table of Contents

 - What is intelligence?
 - Introducing the Abstraction and Reasoning Corpus
 - Kaggle Solutions

## What is the goal of AI Research?

> AI is the science of making machines capable of performing tasks that would require intelligence if done by humans. - Marvin Minsky

<aside class="notes">
Notice is a pretty circular argument. How would we test this?
</aside>

## What is the goal of Introducing the Abstraction and Reasoning Corpus (ARC)?

<div id="left">
> ARC can be used to measure a human-like form of general fluid intelligence and that it enables fair general intelligence comparisons between AI systems and humans.
</div>

<div id="right">
![](img/chollet.jpg)
</div>

## Weaknesses of AI Research

 - Current algorithms are narrow and data hungry
 - Turing Test relies on human judges
 - Lack of agreement biases research to narrow, well defined skills

## Defining Intelligence Currently

From Legg and Hutter:

> Intelligence measures an agentâ€™s ability to *achieve goals* in a *wide range of environments*.

1. Achieve goals 
2. Wide range of environments (Adaptability and Generalization)

Chollet's argument: We've spent too much time on 1.

## What would a good AI adaptability benchmark have?

  - Reproducibility
  - Fairness
  - Scalability
  - Flexibility

## Two ways of thinking about generalization

1. System-centric generalization
  - Most machine learning is here
  - The developer tries to compensate for data not in the dataset
  - Known unknowns

2. Developer-aware generalization
  - Generalizations beyond what the developer expected
  - Unknown unknowns

[](./img/impact.gif)


## The generalization spectrum

 1. Absence of generalization: Classical algorithms. No uncertainty.
 2. Local generalization Most machine learning
 3. Broad generalization: Wozniuk's coffee cup challenge
 4. **Extreme generalization:** Human-level intelligence
 5. Universal generalization: Impossible due to the No Free Lunch Theorem

## Psychometrics Perspective

 - There's a whole field dedicated to measuring intelligence called psychometrics

![](img/psychometrics.png)

## G Factor

- IQ tests are very human centric
- Why not consider octopus camoflauge intelligence?
- Think of G Factor like general athleticism
- There are limits to athletic measurement, we wouldn't measure humans at the bottom of the ocean or Mars
- Humans are incredible efficient at solving 2D and 3D problems but we are terrible at 4D problems

<!-- Why don't we give AI IQ tests? There are too many human centric assumptions -->

## Principles of an AGI Test

- Measure abilities, not skills
- Use a battery of tests, not one
- Set standards on reliability, validity and open standards
- Remove the need for human-level knowledge (bias)
- Focus on skill acquisition efficiency, not skills themselves

## Current trends in AGI evaluation

<div id="left">
- Look at data efficiency in RL
- Most RL tests don't measure reobustness
- Can sample arbitrary amounts of data
- OpenAI Five was brittle to exploits
</div>

<div id="right">
![](img/openai5cheese.png)
</div>

## Measuring the right thing

- DeepBlue didn't get us much closer to AGI
- Neither did the video game challenges
- Real life is a chaotic system, we need to optimize adaptability
- Often, the video game challenges are measuring the ML engineer's intelligence, not the system itself
- Note that a k-nearest neighbour algorithm can solve any task, given enough data

## Priors

- Human intelligence is not hard-coded, but we also aren't blank slates
- To compare intelligences we need to control for experience, priors and difficulty of the task
- Some human priors:
    - Reflex priors (uninteresting to us for this challenge)
    - Metalearning priors (These are the priors we are trying to reverse engineer)
    - High level knowledge priors (e.g. object permenance)
- Machines lack these priors but have hard-coded knowledge

## Priors

- We should make the machine priors as close to human priors as possible
- The less priors you have, the more difficulty the disadvantaged the machine is
- **All priors should be enumerated**

## ARC Priors
- Objectness and elementary physics
    - Object recognition
    - Cohesion
    - Persistance
    - Contact

- Agentness
    - Some objects act **contigently** and **reciprocally**

- Natural numbers up to 10
    - comparison
    - sorting
    - addition and subtraction

- Geoemtry/Topology
    - Distance
    - Orientation
    - In/Out relantionships

All of these should be hard-coded into an AI as a domain specific language

## Contactness

![](img/contactness-before.png)

## Contactness

![](img/contactness-after.png)

## Distance 

![](img/distance.png)

## Distance

![](img/distance2.png)

## Francois Chollet's Definition of Intelligence

> "The intelligence of a system is a measure of it's skill acquisition efficiency over a scope of tasks with respect to priors, experience, and generalization difficulty"

$$I_{I S, s c o p e}^{\theta_{T}}=\underset{T \in s c o p e}{A v g}\left[\omega_{T} \cdot \theta_{T} \sum_{C \in C u r_{T}^{\theta_{T}}}\left[P_{C} \cdot \frac{G D_{I S, T, C}^{\theta_{T}}}{P_{I S, T}^{\theta_{T}}+E_{I S, T, C}^{\theta_{T}}}\right]\right]$$


## How do we measure this type of intelligence

<div id="right">
![](/home/deadhand/Documents/matt-zettlr/img/arc1.png)
</div>

<div id="left">
- This is a different way of thinking about machine learning
- In training, the machine learning model is constant producing skill programs and the task is responding to the skill program itself
- For example, a neural network produces arrays of numbers (the skill program) and the task will give feedback (in the form of gradients) based on the skill programs response
</div>

## The evaluation phase

- The Intelligent System (IS) creates a skill program and then can no longer interact with the system
- IS receives a sum of scaled scores
- IS needs a sufficient skill threshold, the minimum skill needed to solve a task

## Implications of the Intelligence Definition

- Creating an intelligent system can be seen as an optimization problem
- Focuses on broad abilities
- Focuses on program synethesis
- Defines generalization levels
- Can compare humans to AI

## Program Synthesis

- Build a library of primitive functions
- Learn how to compose these primitive functions together to solve problems


## Fair evaluation between Intelligent Systems

- Scope must be well-defined
- Focus on skill-efficiency not maxmium skill
- Only compare intelligence of systems with similar priors

## The ARC Dataset

- Broad
- Developer-aware
- Experience Controlled
- Priors stated
- 400 training tasks/400 public evaluations/200 private

## ARC description

- Up to 10 unique symbols/colors
- Size from 1x1 to 30x30
- Usually 3 trials per test
- A typical human can solve most ARC problems with no previous training
- At least 1 and 3 high IQ humans were able to solve each task


## Differences with Psychometric Tests

- No crystallized knowledge (like NLP or object recognition)
- Greater task diversity
- ARC challenges are not generated programmatically

## What would a possible intelligent system look like?

- Need more human data for a fair comparison
- Deep learning won't work here
- Program synthesis important
- Make a Domain Specific Language (DSL) to describe all possible situations
- Generate candidate programs
- Select top 3 candidates

## Weaknesses & Future Refinement

- ARC solve could have human-like intelligent, or not!
- Generalization difficult not quantified
- Test validaty not established
- Dataset diversity is limited
- Evalutaion is overly close-ended
- Priors may not be well captured in ARC

## The Kaggle competition

 - 20k in prize money
 - Chollet would be surprised if 20% of tasks in the private set were solved
 
## 1st place by Johan Sokrates Wind

 - 20.6% solved
 - Implemented the first 100 training tasks by hand, chunking the solutions into useful functions
 - Made a domain specific language (DSL) and >10k of C++ code multihreaded
 - Used a directed acyclic graph to compose combinations together

## 2nd place by Alejandro de Miquel Bleier, Roderic Guigo Corominas and Yuji Ariyasu
 
 - 19.7% solved
 - Was less than 2% solved for the first 6 weeks
 - Used a short of guided evolution strategy, applying random operations in the training loop and keeping the top 3 results
 - Correctness was based on pixel-wise distance
 
## 3rd palce by Vlad Golubev and Ilia

- Similar to the others

## AI Effect
<!-- Should I keep? -->

McCorduck [61] AI Effect: "Every time somebody figured out how to make a computer do something...there was a chorus of critics to say 'that's not thinking"

## When do you think an algorithm will "solve" on ARC?

## Bibliography
